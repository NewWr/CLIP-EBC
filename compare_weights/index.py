weight_path1 = "/opt/DM/OCT/CLIP_Code/CLIP-EBC/models/clip/_clip/weights/clip_text_encoder_vit_b_16.pth"
weight_path2 = "/opt/DM/OCT/CLIP_Code/RETFound_MAE/hug_model/RETFound_mae_natureCFP.pth"

import torch
import os
from collections import OrderedDict
import re

def load_weights(weight_path):
    """åŠ è½½æƒé‡æ–‡ä»¶"""
    if not os.path.exists(weight_path):
        print(f"âŒ æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {weight_path}")
        return None
    
    try:
        weights = torch.load(weight_path, map_location='cpu', weights_only=False)
        print(f"âœ… æˆåŠŸåŠ è½½: {weight_path}")
        return weights
    except Exception as e:
        print(f"âŒ åŠ è½½æƒé‡æ–‡ä»¶å¤±è´¥ {weight_path}: {e}")
        return None

def normalize_layer_name(layer_name):
    """æ ‡å‡†åŒ–å±‚åç§°ï¼Œå¤„ç†ä¸åŒå‘½åçº¦å®š"""
    # ç§»é™¤å¸¸è§çš„å‰ç¼€
    prefixes_to_remove = [
        'model.', 'module.', 'encoder.', 'visual.', 'vision_model.',
        'backbone.', 'feature_extractor.', 'base_model.'
    ]
    
    normalized = layer_name
    for prefix in prefixes_to_remove:
        if normalized.startswith(prefix):
            normalized = normalized[len(prefix):]
            break
    
    # æ ‡å‡†åŒ–å¸¸è§çš„å±‚åç§°æ¨¡å¼
    replacements = {
        'transformer.resblocks': 'blocks',
        'transformer.layers': 'blocks',
        'layers': 'blocks',
        'resblocks': 'blocks',
        'attn.': 'attention.',
        'self_attn.': 'attention.',
        'multihead_attn.': 'attention.',
        'ln_': 'norm',
        'layernorm': 'norm',
        'layer_norm': 'norm',
        'mlp.c_fc': 'mlp.fc1',
        'mlp.c_proj': 'mlp.fc2',
        'mlp.linear1': 'mlp.fc1',
        'mlp.linear2': 'mlp.fc2'
    }
    
    for old, new in replacements.items():
        normalized = normalized.replace(old, new)
    
    return normalized

def extract_encoder_architecture(weights, name):
    """æå–encoderéƒ¨åˆ†çš„æ¶æ„ä¿¡æ¯"""
    if weights is None:
        return None
    
    # å¤„ç†ä¸åŒçš„æƒé‡æ–‡ä»¶æ ¼å¼
    if isinstance(weights, dict):
        if 'state_dict' in weights:
            state_dict = weights['state_dict']
        elif 'model' in weights:
            state_dict = weights['model']
        else:
            state_dict = weights
    else:
        state_dict = weights
    
    encoder_architecture = OrderedDict()
    
    # å®šä¹‰encoderç›¸å…³çš„å…³é”®è¯
    encoder_keywords = [
        'encoder', 'visual', 'vision', 'backbone', 'feature',
        'transformer', 'blocks', 'layers', 'resblocks',
        'attention', 'attn', 'mlp', 'norm', 'ln_', 'layernorm',
        'patch_embed', 'pos_embed', 'cls_token', 'positional_embedding'
    ]
    
    if isinstance(state_dict, dict):
        for key, value in state_dict.items():
            # æ£€æŸ¥æ˜¯å¦ä¸ºencoderç›¸å…³çš„å±‚
            key_lower = key.lower()
            is_encoder_layer = any(keyword in key_lower for keyword in encoder_keywords)
            
            # æ’é™¤æ˜æ˜¾çš„éencoderå±‚ï¼ˆå¦‚åˆ†ç±»å¤´ã€è§£ç å™¨ç­‰ï¼‰
            exclude_keywords = ['head', 'classifier', 'fc', 'decoder', 'text']
            is_excluded = any(exclude in key_lower for exclude in exclude_keywords)
            
            if is_encoder_layer and not is_excluded:
                if hasattr(value, 'shape'):
                    normalized_key = normalize_layer_name(key)
                    encoder_architecture[normalized_key] = tuple(value.shape)
    
    print(f"ğŸ“Š {name} encoderéƒ¨åˆ†åŒ…å« {len(encoder_architecture)} ä¸ªå‚æ•°å±‚")
    return encoder_architecture

def find_matching_layers(arch1, arch2):
    """å¯»æ‰¾ä¸¤ä¸ªæ¶æ„ä¸­å¯èƒ½åŒ¹é…çš„å±‚"""
    matches = []
    unmatched_1 = set(arch1.keys())
    unmatched_2 = set(arch2.keys())
    
    # ç²¾ç¡®åŒ¹é…
    for key1 in list(unmatched_1):
        if key1 in unmatched_2:
            matches.append((key1, key1, 'exact'))
            unmatched_1.remove(key1)
            unmatched_2.remove(key1)
    
    # æ¨¡ç³ŠåŒ¹é… - åŸºäºå±‚çš„åŠŸèƒ½å’Œä½ç½®
    for key1 in list(unmatched_1):
        best_match = None
        best_score = 0
        
        for key2 in unmatched_2:
            # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
            score = 0
            
            # æå–æ•°å­—ï¼ˆå±‚ç´¢å¼•ï¼‰
            nums1 = re.findall(r'\d+', key1)
            nums2 = re.findall(r'\d+', key2)
            if nums1 and nums2 and nums1 == nums2:
                score += 3
            
            # æ£€æŸ¥å…³é”®è¯åŒ¹é…
            key_words1 = set(re.split(r'[._]', key1.lower()))
            key_words2 = set(re.split(r'[._]', key2.lower()))
            common_words = key_words1.intersection(key_words2)
            score += len(common_words)
            
            # å½¢çŠ¶åŒ¹é…
            if arch1[key1] == arch2[key2]:
                score += 5
            
            if score > best_score and score >= 3:  # æœ€ä½åŒ¹é…é˜ˆå€¼
                best_score = score
                best_match = key2
        
        if best_match:
            matches.append((key1, best_match, 'fuzzy'))
            unmatched_1.remove(key1)
            unmatched_2.remove(best_match)
    
    return matches, unmatched_1, unmatched_2

def compare_encoder_architectures(arch1, arch2):
    """è¯¦ç»†æ¯”è¾ƒä¸¤ä¸ªencoderæ¶æ„"""
    print("\n" + "="*60)
    print("ğŸ” Encoderæ¶æ„å¯¹æ¯”åˆ†æ")
    print("="*60)
    
    if arch1 is None or arch2 is None:
        print("âŒ æ— æ³•è¿›è¡Œæ¯”è¾ƒï¼šæƒé‡æ–‡ä»¶åŠ è½½å¤±è´¥")
        return False
    
    print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   æƒé‡æ–‡ä»¶1 encoderå±‚æ•°: {len(arch1)}")
    print(f"   æƒé‡æ–‡ä»¶2 encoderå±‚æ•°: {len(arch2)}")
    
    # å¯»æ‰¾åŒ¹é…çš„å±‚
    matches, unmatched_1, unmatched_2 = find_matching_layers(arch1, arch2)
    
    print(f"   åŒ¹é…çš„å±‚æ•°: {len(matches)}")
    print(f"   æƒé‡1ä¸­æœªåŒ¹é…: {len(unmatched_1)}")
    print(f"   æƒé‡2ä¸­æœªåŒ¹é…: {len(unmatched_2)}")
    
    # æ˜¾ç¤ºåŒ¹é…çš„å±‚
    if matches:
        print(f"\nâœ… åŒ¹é…çš„å±‚ ({len(matches)}ä¸ª):")
        exact_matches = [m for m in matches if m[2] == 'exact']
        fuzzy_matches = [m for m in matches if m[2] == 'fuzzy']
        
        if exact_matches:
            print(f"\n   ç²¾ç¡®åŒ¹é… ({len(exact_matches)}ä¸ª):")
            for i, (key1, key2, _) in enumerate(exact_matches[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
                shape1, shape2 = arch1[key1], arch2[key2]
                status = "âœ…" if shape1 == shape2 else "âŒ"
                print(f"   {i:2d}. {key1} -> {key2} {status}")
                if shape1 != shape2:
                    print(f"       å½¢çŠ¶: {shape1} vs {shape2}")
            if len(exact_matches) > 10:
                print(f"       ... è¿˜æœ‰ {len(exact_matches) - 10} ä¸ªç²¾ç¡®åŒ¹é…")
        
        if fuzzy_matches:
            print(f"\n   æ¨¡ç³ŠåŒ¹é… ({len(fuzzy_matches)}ä¸ª):")
            for i, (key1, key2, _) in enumerate(fuzzy_matches[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                shape1, shape2 = arch1[key1], arch2[key2]
                status = "âœ…" if shape1 == shape2 else "âŒ"
                print(f"   {i:2d}. {key1} -> {key2} {status}")
                if shape1 != shape2:
                    print(f"       å½¢çŠ¶: {shape1} vs {shape2}")
            if len(fuzzy_matches) > 5:
                print(f"       ... è¿˜æœ‰ {len(fuzzy_matches) - 5} ä¸ªæ¨¡ç³ŠåŒ¹é…")
    
    # æ˜¾ç¤ºæœªåŒ¹é…çš„å±‚
    if unmatched_1:
        print(f"\nğŸš¨ æƒé‡æ–‡ä»¶1ä¸­æœªåŒ¹é…çš„å±‚ ({len(unmatched_1)}ä¸ª):")
        for i, key in enumerate(sorted(unmatched_1)[:10], 1):
            print(f"   {i:2d}. {key} -> {arch1[key]}")
        if len(unmatched_1) > 10:
            print(f"       ... è¿˜æœ‰ {len(unmatched_1) - 10} ä¸ªæœªåŒ¹é…å±‚")
    
    if unmatched_2:
        print(f"\nğŸš¨ æƒé‡æ–‡ä»¶2ä¸­æœªåŒ¹é…çš„å±‚ ({len(unmatched_2)}ä¸ª):")
        for i, key in enumerate(sorted(unmatched_2)[:10], 1):
            print(f"   {i:2d}. {key} -> {arch2[key]}")
        if len(unmatched_2) > 10:
            print(f"       ... è¿˜æœ‰ {len(unmatched_2) - 10} ä¸ªæœªåŒ¹é…å±‚")
    
    # æ£€æŸ¥å½¢çŠ¶ä¸åŒ¹é…
    shape_mismatches = [(k1, k2) for k1, k2, _ in matches if arch1[k1] != arch2[k2]]
    
    # æœ€ç»ˆç»“è®º
    print(f"\n" + "="*60)
    print(f"ğŸ¯ Encoderæ¶æ„å¯¹æ¯”ç»“è®º")
    print(f"="*60)
    
    total_layers = max(len(arch1), len(arch2))
    match_ratio = len(matches) / total_layers if total_layers > 0 else 0
    
    print(f"åŒ¹é…åº¦: {match_ratio:.2%} ({len(matches)}/{total_layers})")
    
    if match_ratio >= 0.8 and len(shape_mismatches) == 0:
        print("âœ… Encoderæ¶æ„é«˜åº¦ç›¸ä¼¼")
        conclusion = "highly_similar"
    elif match_ratio >= 0.6:
        print("âš ï¸ Encoderæ¶æ„éƒ¨åˆ†ç›¸ä¼¼")
        conclusion = "partially_similar"
    else:
        print("âŒ Encoderæ¶æ„å·®å¼‚è¾ƒå¤§")
        conclusion = "different"
    
    if shape_mismatches:
        print(f"âš ï¸ å‘ç° {len(shape_mismatches)} ä¸ªå½¢çŠ¶ä¸åŒ¹é…")
    
    return conclusion

def main():
    """ä¸»å‡½æ•° - ä¸“æ³¨äºencoderæ¶æ„å¯¹æ¯”"""
    print("ğŸ” å¼€å§‹Encoderæƒé‡æ¶æ„å¯¹æ¯”åˆ†æ...")
    print("="*60)
    
    # åŠ è½½æƒé‡æ–‡ä»¶
    print("ğŸ“‚ åŠ è½½æƒé‡æ–‡ä»¶:")
    weights1 = load_weights(weight_path1)
    weights2 = load_weights(weight_path2)
    
    # æå–encoderæ¶æ„ä¿¡æ¯
    print("\nğŸ—ï¸ æå–Encoderæ¶æ„ä¿¡æ¯:")
    arch1 = extract_encoder_architecture(weights1, "æƒé‡æ–‡ä»¶1")
    arch2 = extract_encoder_architecture(weights2, "æƒé‡æ–‡ä»¶2")
    
    # è¿›è¡Œencoderæ¶æ„å¯¹æ¯”
    result = compare_encoder_architectures(arch1, arch2)
    
    return result

if __name__ == "__main__":
    similarity = main()
    print(f"\nğŸ ç¨‹åºæ‰§è¡Œå®Œæˆï¼ŒEncoderæ¶æ„ç›¸ä¼¼åº¦: {similarity}")