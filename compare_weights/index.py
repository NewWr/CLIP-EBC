weight_path1 = "/opt/DM/OCT/CLIP_Code/CLIP-EBC/models/clip/_clip/weights/clip_text_encoder_vit_b_16.pth"
weight_path2 = "/opt/DM/OCT/CLIP_Code/CLIP-EBC/compare_weights/open_clip_pytorch_model.bin"

import torch
import os
from collections import OrderedDict
import re

def load_weights(weight_path):
    """åŠ è½½æƒé‡æ–‡ä»¶"""
    if not os.path.exists(weight_path):
        print(f"âŒ æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {weight_path}")
        return None
    
    try:
        weights = torch.load(weight_path, map_location='cpu', weights_only=False)
        print(f"âœ… æˆåŠŸåŠ è½½: {weight_path}")
        return weights
    except Exception as e:
        print(f"âŒ åŠ è½½æƒé‡æ–‡ä»¶å¤±è´¥ {weight_path}: {e}")
        return None

def convert_to_timm_convnext_keys(state_dict):
    """å°†æƒé‡æ–‡ä»¶çš„keysè½¬æ¢ä¸ºtimm ConvNextæ ‡å‡†æ ¼å¼"""
    if state_dict is None:
        return None
    
    # å¤„ç†ä¸åŒçš„æƒé‡æ–‡ä»¶æ ¼å¼
    if isinstance(state_dict, dict):
        if 'state_dict' in state_dict:
            original_dict = state_dict['state_dict']
        elif 'model' in state_dict:
            original_dict = state_dict['model']
        else:
            original_dict = state_dict
    else:
        original_dict = state_dict
    
    converted_dict = OrderedDict()
    
    # timm ConvNextæ ‡å‡†å‘½åæ˜ å°„è§„åˆ™
    key_mappings = {
        # Stemå±‚æ˜ å°„
        r'^(visual\.|encoder\.|backbone\.|model\.)?stem\.(\d+)\.': r'stem.\2.',
        r'^(visual\.|encoder\.|backbone\.|model\.)?patch_embed\.(\w+)': r'stem.0.\2',
        r'^(visual\.|encoder\.|backbone\.|model\.)?conv1\.': r'stem.0.',
        
        # Stageå±‚æ˜ å°„ (stages.0, stages.1, stages.2, stages.3)
        r'^(visual\.|encoder\.|backbone\.|model\.)?stages\.(\d+)\.(\d+)\.': r'stages.\2.\3.',
        r'^(visual\.|encoder\.|backbone\.|model\.)?layer(\d+)\.(\d+)\.': lambda m: f'stages.{int(m.group(2))-1}.{m.group(3)}.',
        r'^(visual\.|encoder\.|backbone\.|model\.)?blocks\.(\d+)\.(\d+)\.': r'stages.\2.\3.',
        
        # ConvNext Blockå†…éƒ¨ç»„ä»¶æ˜ å°„
        r'\.(dwconv|depthwise_conv)\.': r'.conv_dw.',
        r'\.(pwconv1|pointwise_conv1)\.': r'.mlp.fc1.',
        r'\.(pwconv2|pointwise_conv2)\.': r'.mlp.fc2.',
        r'\.norm\.': r'.norm.',
        r'\.ln\.': r'.norm.',
        r'\.layer_norm\.': r'.norm.',
        r'\.layernorm\.': r'.norm.',
        r'\.gamma': r'.gamma',
        r'\.layer_scale': r'.gamma',
        
        # åˆ†ç±»å¤´æ˜ å°„
        r'^(visual\.|encoder\.|backbone\.|model\.)?head\.(\w+)': r'head.\2',
        r'^(visual\.|encoder\.|backbone\.|model\.)?classifier\.(\w+)': r'head.\2',
        r'^(visual\.|encoder\.|backbone\.|model\.)?fc\.(\w+)': r'head.\2',
        
        # Normå±‚æ˜ å°„
        r'^(visual\.|encoder\.|backbone\.|model\.)?norm\.(\w+)': r'norm.\2',
        r'^(visual\.|encoder\.|backbone\.|model\.)?ln_final\.(\w+)': r'norm.\2',
        r'^(visual\.|encoder\.|backbone\.|model\.)?final_norm\.(\w+)': r'norm.\2',
    }
    
    print(f"ğŸ”„ å¼€å§‹è½¬æ¢æƒé‡keysä¸ºtimm ConvNextæ ¼å¼...")
    converted_count = 0
    unchanged_count = 0
    
    for original_key, value in original_dict.items():
        converted_key = original_key
        conversion_applied = False
        
        # åº”ç”¨æ˜ å°„è§„åˆ™
        for pattern, replacement in key_mappings.items():
            if callable(replacement):
                # å¤„ç†lambdaå‡½æ•°æ›¿æ¢
                match = re.search(pattern, converted_key)
                if match:
                    converted_key = re.sub(pattern, replacement(match), converted_key)
                    conversion_applied = True
                    break
            else:
                # å¤„ç†å­—ç¬¦ä¸²æ›¿æ¢
                if re.search(pattern, converted_key):
                    converted_key = re.sub(pattern, replacement, converted_key)
                    conversion_applied = True
                    break
        
        # æ¸…ç†å¤šä½™çš„å‰ç¼€
        prefixes_to_remove = [
            'visual.', 'encoder.', 'backbone.', 'model.', 'vision_model.',
            'feature_extractor.', 'base_model.'
        ]
        
        for prefix in prefixes_to_remove:
            if converted_key.startswith(prefix):
                converted_key = converted_key[len(prefix):]
                conversion_applied = True
                break
        
        converted_dict[converted_key] = value
        
        if conversion_applied:
            converted_count += 1
            if converted_count <= 10:  # åªæ˜¾ç¤ºå‰10ä¸ªè½¬æ¢ç¤ºä¾‹
                print(f"  âœ… {original_key} -> {converted_key}")
        else:
            unchanged_count += 1
    
    if converted_count > 10:
        print(f"  ... è¿˜æœ‰ {converted_count - 10} ä¸ªkeysè¢«è½¬æ¢")
    
    print(f"\nğŸ“Š è½¬æ¢ç»Ÿè®¡:")
    print(f"  æ€»keysæ•°é‡: {len(original_dict)}")
    print(f"  å·²è½¬æ¢: {converted_count}")
    print(f"  æœªæ”¹å˜: {unchanged_count}")
    
    return converted_dict

def save_converted_weights(converted_dict, original_path, suffix="_timm_convnext"):
    """ä¿å­˜è½¬æ¢åçš„æƒé‡æ–‡ä»¶"""
    if converted_dict is None:
        print("âŒ æ— æ³•ä¿å­˜ï¼šè½¬æ¢åçš„æƒé‡ä¸ºç©º")
        return None
    
    # ç”Ÿæˆæ–°çš„æ–‡ä»¶è·¯å¾„
    base_path = os.path.splitext(original_path)[0]
    extension = os.path.splitext(original_path)[1]
    new_path = f"{base_path}{suffix}{extension}"
    
    try:
        torch.save(converted_dict, new_path)
        print(f"âœ… è½¬æ¢åçš„æƒé‡å·²ä¿å­˜åˆ°: {new_path}")
        return new_path
    except Exception as e:
        print(f"âŒ ä¿å­˜æƒé‡æ–‡ä»¶å¤±è´¥: {e}")
        return None

def normalize_layer_name(layer_name):
    """æ ‡å‡†åŒ–å±‚åç§°ï¼Œå¤„ç†ä¸åŒå‘½åçº¦å®š"""
    # ç§»é™¤å¸¸è§çš„å‰ç¼€
    prefixes_to_remove = [
        'model.', 'module.', 'encoder.', 'visual.', 'vision_model.',
        'backbone.', 'feature_extractor.', 'base_model.'
    ]
    
    normalized = layer_name
    for prefix in prefixes_to_remove:
        if normalized.startswith(prefix):
            normalized = normalized[len(prefix):]
            break
    
    # æ ‡å‡†åŒ–å¸¸è§çš„å±‚åç§°æ¨¡å¼
    replacements = {
        'transformer.resblocks': 'blocks',
        'transformer.layers': 'blocks',
        'layers': 'blocks',
        'resblocks': 'blocks',
        'attn.': 'attention.',
        'self_attn.': 'attention.',
        'multihead_attn.': 'attention.',
        'ln_': 'norm',
        'layernorm': 'norm',
        'layer_norm': 'norm',
        'mlp.c_fc': 'mlp.fc1',
        'mlp.c_proj': 'mlp.fc2',
        'mlp.linear1': 'mlp.fc1',
        'mlp.linear2': 'mlp.fc2'
    }
    
    for old, new in replacements.items():
        normalized = normalized.replace(old, new)
    
    return normalized

def extract_encoder_architecture(weights, name):
    """æå–encoderéƒ¨åˆ†çš„æ¶æ„ä¿¡æ¯"""
    if weights is None:
        return None
    
    # å¤„ç†ä¸åŒçš„æƒé‡æ–‡ä»¶æ ¼å¼
    if isinstance(weights, dict):
        if 'state_dict' in weights:
            state_dict = weights['state_dict']
        elif 'model' in weights:
            state_dict = weights['model']
        else:
            state_dict = weights
    else:
        state_dict = weights
    
    encoder_architecture = OrderedDict()
    
    # å®šä¹‰encoderç›¸å…³çš„å…³é”®è¯
    encoder_keywords = [
        'encoder', 'visual', 'vision', 'backbone', 'feature',
        'transformer', 'blocks', 'layers', 'resblocks',
        'attention', 'attn', 'mlp', 'norm', 'ln_', 'layernorm',
        'patch_embed', 'pos_embed', 'cls_token', 'positional_embedding'
    ]
    
    if isinstance(state_dict, dict):
        for key, value in state_dict.items():
            # æ£€æŸ¥æ˜¯å¦ä¸ºencoderç›¸å…³çš„å±‚
            key_lower = key.lower()
            is_encoder_layer = any(keyword in key_lower for keyword in encoder_keywords)
            
            # æ’é™¤æ˜æ˜¾çš„éencoderå±‚ï¼ˆå¦‚åˆ†ç±»å¤´ã€è§£ç å™¨ç­‰ï¼‰
            exclude_keywords = ['head', 'classifier', 'fc', 'decoder', 'text']
            is_excluded = any(exclude in key_lower for exclude in exclude_keywords)
            
            if is_encoder_layer and not is_excluded:
                if hasattr(value, 'shape'):
                    normalized_key = normalize_layer_name(key)
                    encoder_architecture[normalized_key] = tuple(value.shape)
    
    print(f"ğŸ“Š {name} encoderéƒ¨åˆ†åŒ…å« {len(encoder_architecture)} ä¸ªå‚æ•°å±‚")
    return encoder_architecture

def find_matching_layers(arch1, arch2):
    """å¯»æ‰¾ä¸¤ä¸ªæ¶æ„ä¸­å¯èƒ½åŒ¹é…çš„å±‚"""
    matches = []
    unmatched_1 = set(arch1.keys())
    unmatched_2 = set(arch2.keys())
    
    # ç²¾ç¡®åŒ¹é…
    for key1 in list(unmatched_1):
        if key1 in unmatched_2:
            matches.append((key1, key1, 'exact'))
            unmatched_1.remove(key1)
            unmatched_2.remove(key1)
    
    # æ¨¡ç³ŠåŒ¹é… - åŸºäºå±‚çš„åŠŸèƒ½å’Œä½ç½®
    for key1 in list(unmatched_1):
        best_match = None
        best_score = 0
        
        for key2 in unmatched_2:
            # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
            score = 0
            
            # æå–æ•°å­—ï¼ˆå±‚ç´¢å¼•ï¼‰
            nums1 = re.findall(r'\d+', key1)
            nums2 = re.findall(r'\d+', key2)
            if nums1 and nums2 and nums1 == nums2:
                score += 3
            
            # æ£€æŸ¥å…³é”®è¯åŒ¹é…
            key_words1 = set(re.split(r'[._]', key1.lower()))
            key_words2 = set(re.split(r'[._]', key2.lower()))
            common_words = key_words1.intersection(key_words2)
            score += len(common_words)
            
            # å½¢çŠ¶åŒ¹é…
            if arch1[key1] == arch2[key2]:
                score += 5
            
            if score > best_score and score >= 3:  # æœ€ä½åŒ¹é…é˜ˆå€¼
                best_score = score
                best_match = key2
        
        if best_match:
            matches.append((key1, best_match, 'fuzzy'))
            unmatched_1.remove(key1)
            unmatched_2.remove(best_match)
    
    return matches, unmatched_1, unmatched_2

def compare_encoder_architectures(arch1, arch2):
    """è¯¦ç»†æ¯”è¾ƒä¸¤ä¸ªencoderæ¶æ„"""
    print("\n" + "="*60)
    print("ğŸ” Encoderæ¶æ„å¯¹æ¯”åˆ†æ")
    print("="*60)
    
    if arch1 is None or arch2 is None:
        print("âŒ æ— æ³•è¿›è¡Œæ¯”è¾ƒï¼šæƒé‡æ–‡ä»¶åŠ è½½å¤±è´¥")
        return False
    
    print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   æƒé‡æ–‡ä»¶1 encoderå±‚æ•°: {len(arch1)}")
    print(f"   æƒé‡æ–‡ä»¶2 encoderå±‚æ•°: {len(arch2)}")
    
    # å¯»æ‰¾åŒ¹é…çš„å±‚
    matches, unmatched_1, unmatched_2 = find_matching_layers(arch1, arch2)
    
    print(f"   åŒ¹é…çš„å±‚æ•°: {len(matches)}")
    print(f"   æƒé‡1ä¸­æœªåŒ¹é…: {len(unmatched_1)}")
    print(f"   æƒé‡2ä¸­æœªåŒ¹é…: {len(unmatched_2)}")
    
    # æ˜¾ç¤ºåŒ¹é…çš„å±‚
    if matches:
        print(f"\nâœ… åŒ¹é…çš„å±‚ ({len(matches)}ä¸ª):")
        exact_matches = [m for m in matches if m[2] == 'exact']
        fuzzy_matches = [m for m in matches if m[2] == 'fuzzy']
        
        if exact_matches:
            print(f"\n   ç²¾ç¡®åŒ¹é… ({len(exact_matches)}ä¸ª):")
            for i, (key1, key2, _) in enumerate(exact_matches[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
                shape1, shape2 = arch1[key1], arch2[key2]
                status = "âœ…" if shape1 == shape2 else "âŒ"
                print(f"   {i:2d}. {key1} -> {key2} {status}")
                if shape1 != shape2:
                    print(f"       å½¢çŠ¶: {shape1} vs {shape2}")
            if len(exact_matches) > 10:
                print(f"       ... è¿˜æœ‰ {len(exact_matches) - 10} ä¸ªç²¾ç¡®åŒ¹é…")
        
        if fuzzy_matches:
            print(f"\n   æ¨¡ç³ŠåŒ¹é… ({len(fuzzy_matches)}ä¸ª):")
            for i, (key1, key2, _) in enumerate(fuzzy_matches[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                shape1, shape2 = arch1[key1], arch2[key2]
                status = "âœ…" if shape1 == shape2 else "âŒ"
                print(f"   {i:2d}. {key1} -> {key2} {status}")
                if shape1 != shape2:
                    print(f"       å½¢çŠ¶: {shape1} vs {shape2}")
            if len(fuzzy_matches) > 5:
                print(f"       ... è¿˜æœ‰ {len(fuzzy_matches) - 5} ä¸ªæ¨¡ç³ŠåŒ¹é…")
    
    # æ˜¾ç¤ºæœªåŒ¹é…çš„å±‚
    if unmatched_1:
        print(f"\nğŸš¨ æƒé‡æ–‡ä»¶1ä¸­æœªåŒ¹é…çš„å±‚ ({len(unmatched_1)}ä¸ª):")
        for i, key in enumerate(sorted(unmatched_1)[:10], 1):
            print(f"   {i:2d}. {key} -> {arch1[key]}")
        if len(unmatched_1) > 10:
            print(f"       ... è¿˜æœ‰ {len(unmatched_1) - 10} ä¸ªæœªåŒ¹é…å±‚")
    
    if unmatched_2:
        print(f"\nğŸš¨ æƒé‡æ–‡ä»¶2ä¸­æœªåŒ¹é…çš„å±‚ ({len(unmatched_2)}ä¸ª):")
        for i, key in enumerate(sorted(unmatched_2)[:10], 1):
            print(f"   {i:2d}. {key} -> {arch2[key]}")
        if len(unmatched_2) > 10:
            print(f"       ... è¿˜æœ‰ {len(unmatched_2) - 10} ä¸ªæœªåŒ¹é…å±‚")
    
    # æ£€æŸ¥å½¢çŠ¶ä¸åŒ¹é…
    shape_mismatches = [(k1, k2) for k1, k2, _ in matches if arch1[k1] != arch2[k2]]
    
    # æœ€ç»ˆç»“è®º
    print(f"\n" + "="*60)
    print(f"ğŸ¯ Encoderæ¶æ„å¯¹æ¯”ç»“è®º")
    print(f"="*60)
    
    total_layers = max(len(arch1), len(arch2))
    match_ratio = len(matches) / total_layers if total_layers > 0 else 0
    
    print(f"åŒ¹é…åº¦: {match_ratio:.2%} ({len(matches)}/{total_layers})")
    
    if match_ratio >= 0.8 and len(shape_mismatches) == 0:
        print("âœ… Encoderæ¶æ„é«˜åº¦ç›¸ä¼¼")
        conclusion = "highly_similar"
    elif match_ratio >= 0.6:
        print("âš ï¸ Encoderæ¶æ„éƒ¨åˆ†ç›¸ä¼¼")
        conclusion = "partially_similar"
    else:
        print("âŒ Encoderæ¶æ„å·®å¼‚è¾ƒå¤§")
        conclusion = "different"
    
    if shape_mismatches:
        print(f"âš ï¸ å‘ç° {len(shape_mismatches)} ä¸ªå½¢çŠ¶ä¸åŒ¹é…")
    
    return conclusion

def main():
    """ä¸»å‡½æ•° - ä¸“æ³¨äºencoderæ¶æ„å¯¹æ¯”å’Œæƒé‡è½¬æ¢"""
    print("ğŸ” å¼€å§‹Encoderæƒé‡æ¶æ„å¯¹æ¯”åˆ†æå’Œtimm ConvNextæ ¼å¼è½¬æ¢...")
    print("="*60)
    
    # åŠ è½½æƒé‡æ–‡ä»¶
    print("ğŸ“‚ åŠ è½½æƒé‡æ–‡ä»¶:")
    weights1 = load_weights(weight_path1)
    weights2 = load_weights(weight_path2)
    
    # è½¬æ¢æƒé‡keysä¸ºtimm ConvNextæ ¼å¼
    print("\nğŸ”„ è½¬æ¢æƒé‡keysä¸ºtimm ConvNextæ ¼å¼:")
    if weights1 is not None:
        print("\nå¤„ç†æƒé‡æ–‡ä»¶1:")
        converted_weights1 = convert_to_timm_convnext_keys(weights1)
        if converted_weights1 is not None:
            save_converted_weights(converted_weights1, weight_path1)
    
    if weights2 is not None:
        print("\nå¤„ç†æƒé‡æ–‡ä»¶2:")
        converted_weights2 = convert_to_timm_convnext_keys(weights2)
        if converted_weights2 is not None:
            save_converted_weights(converted_weights2, weight_path2)
    
    # æå–encoderæ¶æ„ä¿¡æ¯
    print("\nğŸ—ï¸ æå–Encoderæ¶æ„ä¿¡æ¯:")
    arch1 = extract_encoder_architecture(weights1, "æƒé‡æ–‡ä»¶1")
    arch2 = extract_encoder_architecture(weights2, "æƒé‡æ–‡ä»¶2")
    
    # è¿›è¡Œencoderæ¶æ„å¯¹æ¯”
    result = compare_encoder_architectures(arch1, arch2)
    
    return result

if __name__ == "__main__":
    similarity = main()
    print(f"\nğŸ ç¨‹åºæ‰§è¡Œå®Œæˆï¼ŒEncoderæ¶æ„ç›¸ä¼¼åº¦: {similarity}")